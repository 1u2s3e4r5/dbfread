dbfget - Python library for getting data out of DBF files
=========================================================

Requires Python 2.7 or 3.2 (works in both without change)

License: MIT

Latest version of the source code: https://github.com/olemb/dbfget/


Example
-------

::

    >>> import dbfget
    >>> table = dbfget.read('cables.dbf')

This returns a table object, which is a subclass of list. The list
contains all records from the table as normal Python dictionaries::

    >>> len(table)
    552
    >>> for rec in table:
    ...     print rec['CABLE'], rec['LENGTH']

By default, all records are read into memory. If you would instead
like to iterate through them as they come off the file, you can use
the ```load=False`` option::

    >>> table = dbfget.read('cables.dbf', load=False)
    >>> for rec in table:
    ...     print rec['CABLE'], rec['LENGTH']

When records are loaded, the table behaves like a list. When records
are not loaded it behaves like an iterator. (It is still a list, just an
empty one, so len(table) will return 0 even though there are records in
the file.)

You can use the load() and unload() methods to load and unload records.
This will also switch between list and iteration protocols.

A tool is included in the ```examples``` directory to convert dbf into
sqlite, for example::

    dbf2sqlite -o stamnett.sqlite kabreg.dbf endreg.dbf

This will create one table for each dbf file. You can also omit the
``-o stamnett.sqlite`` option to have the SQL printed directly to
stdout.


Status
------

This code in various incarnations has been in production at the
University of Tromsø since 2001. The current version reads all data
generated by Telemator (http://www.telemator.no/), which uses Visual
Foxpro (as far as I can tell) and employs a wide range of data types.

The library has not been widely tested on other data, but I intend for
it to be able to read ANY DBF file. If you have a file it can't read,
or find a bug, I'd love to hear from you.


Installing
----------

Python 2::

  sudo python setup.py install

Python 3::

  sudo python3 setup.py install
    

Supported field types
----------------------

=  ==========  ====================================================================
:  Field type   Converted to
=  ==========  ====================================================================
0  flags       int
C  text        unicode string
D  date        datetime.date or None
F  float       float or None
I  integer     int or None
L  logical     True, False or None
M  memo        unicode string (memo type) or byte string (picture and object type)
N  numeric     int, float or None
T  time        datetime.datetime
=  ==========  ====================================================================

    
Options
-------

By default, dbfget.read() will try to guess the character encoding
from the language_driver byte. This doesn't always succeed. You can
override the encoding with the option::

   encoding='latin1'

If you want records returned as objects instead of dictionaries, you
can use this option::

   recfactory=dbfget.RecObject

If you combine that with this option::

   lowernames=True

the simple example above becomes::

    >>> import dbfget
    >>> table = dbfget.read('cables.dbf',
                            recfactory=dbfget.RecObject,
                            lowernames=True)
    >>> for rec in table:
    ...     print rec.cable, rec.length

The ``recfactory`` option takes any callable which accepts a list of
```(name, value)``` tuples, for example::

   recfactory=collections.OrderedDict

One last option. By default, dbfget will assume that you've copied the
DBF files from a windows file system, and that the file name casing is
all scrambled. Thus, it will treat ```Cables.FPT``` as the same file
as ```CABLES.fpt```. You can turn off this behaviour with::

   ignorecase=False

There is also an "undocumented" option, which I use mostly for debugging::

   raw=True   # Returns all data values as raw bytestrings


Table attributes
----------------

The table object has a lot of attributes, which can be useful for
introspection. Some simple ones::

    >>> table.name
    'cables'
    
    >>> table.date
    datetime.date(2012, 7, 11)

    >>> table.encoding
    'cp1252'

A list of field names can be useful for producing CSV files, for example::

    >>> table.field_names
    [u'CABLE', u'OWNER', u'USAGE', u'CORETYPE', u'NUMCORES',
    u'END_A', u'END_B', u'LENGTH', u'DTPLACED', u'COVERAGE', u'REMARKM',
    u'TYPECODE', u'BROKEN', u'AUTROUTBLK', u'UPDWHEN', u'UPDVER', u'UPDUSER',
    u'SPEED', u'TSLST]

The file header and field headers are namedtuples::

    >>> table.header
    DBFHeader(dbversion=48, year=12, month=7, day=11, numrecords=555,
    headerlen=2408, recordlen=632, reserved1=0, incomplete_transaction=0,
    encryption_flag=0, free_record_thread=0, reserved2=0, reserved3=0,
    mdx_flag=3, language_driver=3, reserved4=0)
    
    >>> table.fields
    [DBFField(name=u'CABLE', type=u'C', address=1, length=25, decimal_count=0,
    reserved1=0, workarea_id=0, reserved2=0, reserved3=0, set_fields_flag=0,
    reserved4='\x00\x00\x00\x00\x00\x00\x00', index_field_flag=0),
    ... etc. ...]


Contact
--------

Ole Martin Bjørndalen - ombdalen@gmail.com - http://nerdly.info/ole/
